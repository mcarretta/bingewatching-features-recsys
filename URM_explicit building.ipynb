{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.dataset import Dataset, ContentWiseImpressions, read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.dataset import Dataset, ContentWiseImpressions, read_dataset\n",
    "from SerialContentAnalysisFunctions import *\n",
    "DATASET_VARIANT = ContentWiseImpressions.Variant.CW10M\n",
    "dataset: ContentWiseImpressions = read_dataset(DATASET_VARIANT, use_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/ContentWiseImpressions/CW10M-CSV/interactions.csv\"\n",
    "d = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "\n",
    "__STYLE = \"whitegrid\"\n",
    "__CONTEXT = \"paper\"  # change to \"paper\" when creating figures for the paper\n",
    "__FIG_SIZE_WIDTH = (\n",
    "    16\n",
    "    if __CONTEXT == \"paper\"\n",
    "    else 20\n",
    ")\n",
    "__FIG_SIZE_HEIGHT = (\n",
    "    9\n",
    "    if __CONTEXT == \"paper\"\n",
    "    else 20\n",
    ")\n",
    "__FIG_DPI = 150\n",
    "\n",
    "sns.set_context(__CONTEXT)\n",
    "sns.set_style(__STYLE)\n",
    "\n",
    "\n",
    "\n",
    "def _get_urm_plots_filenames(\n",
    "        plot_filepath: str,\n",
    "        norm_plot_filepath: str\n",
    ") -> Tuple[str, str]:\n",
    "    urm_heatmap_with_means_filename = os.path.join(\n",
    "        plot_filepath,\n",
    "        f\"urm_with_means.png\"\n",
    "    )\n",
    "    norm_urm_heatmap_with_means_filename = os.path.join(\n",
    "        norm_plot_filepath,\n",
    "        f\"urm_with_means.png\"\n",
    "    )\n",
    "\n",
    "    return urm_heatmap_with_means_filename, norm_urm_heatmap_with_means_filename\n",
    "\n",
    "\n",
    "def urm_plots_exists(\n",
    "        plot_path: str,\n",
    "        norm_plot_path: str,\n",
    ") -> bool:\n",
    "    filename, norm_filename = _get_urm_plots_filenames(\n",
    "        plot_filepath=plot_path,\n",
    "        norm_plot_filepath=norm_plot_path,\n",
    "    )\n",
    "\n",
    "    return os.path.exists(norm_filename) and os.path.exists(filename)\n",
    "\n",
    "\n",
    "def generate_urm_heatmap_plot(\n",
    "        urm: sp.csr_matrix,\n",
    "        user_popularity: np.ndarray,\n",
    "        item_popularity: np.ndarray,\n",
    "        plot_path: str,\n",
    "        norm_plot_path: str,\n",
    "        \n",
    ") -> None:\n",
    "    \"\"\"\n",
    "         The plot is expected to be something like this. It is divided in a 4x3 grid where\n",
    "          * The URM heatmap color-bar goes in 0,2\n",
    "\n",
    "          * The URM heatmap goes in 1,2\n",
    "\n",
    "          * The URM User-Popularity Boxplot goes in 1,0\n",
    "          * The URM User-Popularity Scatter plot goes in 1,1\n",
    "          * The URM Item-Popularity Boxplot goes in 2,2\n",
    "          * The URM Item-Popularity Scatter plot goes in 3,2\n",
    "\n",
    "          * E represent empty cells of the map.\n",
    "\n",
    "               0           1           2       \n",
    "           ------------------------------------\n",
    "         0 |   E      |   E      |  URM       |\n",
    "           |   E      |   E      |  color-bar |\n",
    "           |__________|__________|____________|\n",
    "           | User-Pop | User-Pop |  URM       |\n",
    "           | Boxplot  | Scatter  |  Heatmap   |\n",
    "           |          |          |            |\n",
    "         1 |          |          |            |\n",
    "           |          |          |            |\n",
    "           |          |          |            |\n",
    "           |__________|__________|____________|\n",
    "         2 |   E      |   E      |  Item-Pop  |\n",
    "           |   E      |   E      |   Scatter  |\n",
    "           |__________|__________|____________|\n",
    "         3 |   E      |   E      |  Item-Pop  |\n",
    "           |   E      |   E      |   Boxplot  |\n",
    "           |__________|__________|____________|\n",
    "    \"\"\"\n",
    "    (\n",
    "        urm_heatmap_with_means_filename,\n",
    "        norm_urm_heatmap_with_means_filename\n",
    "    ) = _get_urm_plots_filenames(\n",
    "        plot_filepath=plot_path,\n",
    "        norm_plot_filepath=norm_plot_path,\n",
    "    )\n",
    "\n",
    "    for normalize in [True, False]:\n",
    "        if normalize and os.path.exists(norm_urm_heatmap_with_means_filename):\n",
    "            continue\n",
    "\n",
    "        if not normalize and os.path.exists(urm_heatmap_with_means_filename):\n",
    "            continue\n",
    "\n",
    "        num_rows = 4\n",
    "        num_cols = 3\n",
    "        height_rows_ratios = [5, 75, 10, 10]\n",
    "        width_cols_ratios = [10, 10, 80]\n",
    "\n",
    "        fig: plt.Figure = plt.figure(\n",
    "            figsize=(__FIG_SIZE_WIDTH, __FIG_SIZE_WIDTH),\n",
    "            dpi=__FIG_DPI\n",
    "        )\n",
    "        gs = plt.GridSpec(\n",
    "            nrows=num_rows,\n",
    "            ncols=num_cols,\n",
    "            figure=fig,\n",
    "            height_ratios=height_rows_ratios,\n",
    "            width_ratios=width_cols_ratios,\n",
    "        )\n",
    "\n",
    "        ax_urm_heatmap_color_bar: plt.Axes = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "        ax_urm_heatmap: plt.Axes = fig.add_subplot(\n",
    "            gs[1, 2]\n",
    "        )\n",
    "\n",
    "        ax_urm_user_popularity_boxplot: plt.Axes = fig.add_subplot(\n",
    "            gs[1, 0],\n",
    "        )\n",
    "        ax_urm_user_popularity_scatter: plt.Axes = fig.add_subplot(\n",
    "            gs[1, 1],\n",
    "            sharey=ax_urm_heatmap\n",
    "        )\n",
    "\n",
    "        ax_urm_item_popularity_scatter: plt.Axes = fig.add_subplot(\n",
    "            gs[2, 2],\n",
    "            sharex=ax_urm_heatmap\n",
    "        )\n",
    "        ax_urm_item_popularity_boxplot: plt.Axes = fig.add_subplot(\n",
    "            gs[3, 2],\n",
    "        )\n",
    "\n",
    "        sort_urm_and_item_weights_by_popularity = True\n",
    "        if sort_urm_and_item_weights_by_popularity:\n",
    "            popular_user_indices_desc = np.flip(np.argsort(user_popularity))\n",
    "            popular_item_indices_desc = np.flip(np.argsort(item_popularity))\n",
    "\n",
    "            urm = urm[popular_user_indices_desc, :][:, popular_item_indices_desc]\n",
    "            user_popularity = user_popularity[popular_user_indices_desc]\n",
    "            item_popularity = item_popularity[popular_item_indices_desc]\n",
    "\n",
    "        plot_objects = [\n",
    "            [\n",
    "                ax_urm_heatmap_color_bar, ax_urm_heatmap, urm.toarray(), None, None,\n",
    "                \"User-Rating Matrix\",\n",
    "                ax_urm_user_popularity_boxplot, user_popularity, \"User Popularity\",\n",
    "                ax_urm_user_popularity_scatter, user_popularity, \"User Popularity\",\n",
    "                ax_urm_item_popularity_boxplot, item_popularity, \"Item Popularity\",\n",
    "                ax_urm_item_popularity_scatter, item_popularity, \"Item Popularity\",\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "        num_users, num_items = urm.shape\n",
    "        for objects in plot_objects:\n",
    "            (\n",
    "                ax_heatmap_color_bar, ax_heatmap, heatmap_data, heatmap_min, heatmap_max, heatmap_title,\n",
    "                ax_user_boxplot, user_boxplot_data, user_boxplot_title,\n",
    "                ax_user_scatter, user_scatter_data, user_scatter_title,\n",
    "                ax_item_boxplot, item_boxplot_data, item_boxplot_title,\n",
    "                ax_item_scatter, item_scatter_data, item_scatter_title,\n",
    "            ) = objects\n",
    "\n",
    "            sns.heatmap(\n",
    "                data=heatmap_data,\n",
    "                ax=ax_heatmap,\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar_ax=ax_heatmap_color_bar,\n",
    "                cbar_kws={\"orientation\": \"horizontal\"},\n",
    "                vmin=heatmap_min,\n",
    "                vmax=heatmap_max,\n",
    "            )\n",
    "\n",
    "            sns.boxplot(\n",
    "                x=user_boxplot_data,\n",
    "                color=\"orange\",\n",
    "                ax=ax_user_boxplot,\n",
    "            )\n",
    "            sns.scatterplot(\n",
    "                y=np.arange(num_users),\n",
    "                x=user_scatter_data,\n",
    "                color=\"orange\",\n",
    "                ax=ax_user_scatter,\n",
    "            )\n",
    "\n",
    "            sns.boxplot(\n",
    "                y=item_boxplot_data,\n",
    "                color=\"red\",\n",
    "                ax=ax_item_boxplot,\n",
    "            )\n",
    "            sns.scatterplot(\n",
    "                x=np.arange(num_items),\n",
    "                y=item_scatter_data,\n",
    "                color=\"red\",\n",
    "                ax=ax_item_scatter,\n",
    "            )\n",
    "\n",
    "            ax_heatmap.set_xlabel(\"Item Ids\")\n",
    "            ax_heatmap.set_ylabel(\"User Ids\")\n",
    "\n",
    "            ax_user_boxplot.tick_params(labelleft=False, labelright=False)\n",
    "            ax_user_scatter.tick_params(labelleft=False, labelright=False)\n",
    "\n",
    "            ax_item_boxplot.tick_params(labeltop=False, labelbottom=False)\n",
    "            ax_item_scatter.tick_params(labeltop=False, labelbottom=False)\n",
    "\n",
    "            ax_heatmap.set_title(heatmap_title)\n",
    "\n",
    "            ax_user_boxplot.set_title(user_boxplot_title)\n",
    "            ax_user_scatter.set_title(user_scatter_title)\n",
    "\n",
    "            ax_item_boxplot.set_title(item_boxplot_title)\n",
    "            ax_item_scatter.set_title(item_scatter_title)\n",
    "\n",
    "        plot_title = (\n",
    "            \"Normalized URM Visualization\"\n",
    "            if normalize\n",
    "            else \"URM Visualization\"\n",
    "        )\n",
    "#         for key, value in plot_title_extras.items():\n",
    "#             plot_title += f\"\\n* {key}={value}\"\n",
    "\n",
    "        fig.suptitle(\n",
    "            t=plot_title\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.savefig(\n",
    "            norm_urm_heatmap_with_means_filename\n",
    "            if normalize\n",
    "            else urm_heatmap_with_means_filename\n",
    "        )\n",
    "    \n",
    "        fig.clear()\n",
    "        plt.close(fig=fig)\n",
    "    \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_popularity = np.ediff1d(dataset.URM[\"train\"].indptr)\n",
    "item_popularity = np.ediff1d(dataset.URM[\"train\"].tocsc().indptr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_urm_heatmap_plot(dataset.URM[\"train\"], user_popularity, item_popularity,\n",
    "                         \"/plots\", \"/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38875x18279 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 532985 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.URM[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matteo/Desktop/serial-content-analysis/parquets/ts_differential_df_50_4hours.parquet\n",
      "Loading existing parquet file in parquets/ts_differential_df_50_4hours_train.parquet\n",
      "Df_bw loaded\n"
     ]
    }
   ],
   "source": [
    "urm_extended = elasticnet_URM_train_with_bingewatching(dataset.URM[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38876, 18280)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm = urm_extended.todense()\n",
    "urm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binge_worthy = urm[-1, :]\n",
    "binge_worthy[binge_worthy > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, ..., 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binge_watchers = urm[:, -1]\n",
    "binge_watchers[binge_watchers > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=38876, minmax=(array([0], dtype=int64), array([1], dtype=int64)), mean=array([0.02711184]), variance=array([0.02637747]), skewness=array([5.82341119]), kurtosis=array([31.91211785]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(binge_watchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=1054, minmax=(array([1], dtype=int64), array([1], dtype=int64)), mean=array([1.]), variance=array([0.]), skewness=array([0.]), kurtosis=array([-3.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(binge_watchers[binge_watchers > 0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=18280, minmax=(array([0], dtype=int64), array([1], dtype=int64)), mean=array([0.01247265]), variance=array([0.01231775]), skewness=array([8.78567406]), kurtosis=array([75.18806878]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(binge_worthy.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=228, minmax=(array([1], dtype=int64), array([1], dtype=int64)), mean=array([1.]), variance=array([0.]), skewness=array([0.]), kurtosis=array([-3.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(binge_worthy[binge_worthy > 0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(dataset.URM[\"train\"].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(dataset.URM[\"validation\"].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(dataset.URM[\"test\"].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm.sum(axis=0)\n",
    "URM_train = dataset.URM[\"train\"]\n",
    "URM_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.URM[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.URM[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bw = get_timestamp_differential_dataframe(df=None, percentage=50, session_threshold_hours=4, train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _read_dictionary(local_file_path: str) -> dict:\n",
    "    with open(local_file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "translation_user_id_index_urm = _read_dictionary(os.path.join(os.getcwd(),\n",
    "                                       \"data\",\n",
    "                                       \"ContentWiseImpressions\",\n",
    "                                       \"CW10M\",\n",
    "                                       \"translation_user_id_index_urm.json\"))\n",
    "translation_series_id_index_urm = _read_dictionary(os.path.join(os.getcwd(),\n",
    "                                       \"data\",\n",
    "                                       \"ContentWiseImpressions\",\n",
    "                                       \"CW10M\",\n",
    "                                       \"translation_series_id_index_urm.json\"))\n",
    "\n",
    "user_indices = np.unique(df_bw.user_id.values, return_index=True)[1]\n",
    "# bingewatchers = {translation_user_id_index_urm[user]: bw for user, bw in zip([df_bw.user_id.values[index] for index in sorted(user_indices)],\n",
    "#                                               np.array(df_bw.groupby(\"user_id\").sum().n_bingewatching_sessions_3_to_7.values,\n",
    "#                                                        dtype=int))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_user_id_index_urm[\"42151\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bingewatchers = {}\n",
    "for user, bw in zip([df_bw.user_id.values[index] for index in sorted(user_indices)], np.array(df_bw.groupby(\"user_id\").sum().n_bingewatching_sessions_3_to_7.values, dtype=int)):\n",
    "    print(translation_user_id_index_urm[user], bingewatchers[translation_user_id_index_urm[user]])\n",
    "    bingewatchers[translation_user_id_index_urm[user]] = bw\n",
    "    print(translation_user_id_index_urm[user], bingewatchers[translation_user_id_index_urm[user]])\n",
    "URM_bingewatchers_column_array = np.zeros((URM_train.shape[0]+1, 1), dtype=int)\n",
    "\n",
    "for k, i in bingewatchers.items():\n",
    "    URM_bingewatchers_column_array[k] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bingeworthy row to be added at the bottom of the URM\n",
    "series_indices = np.unique(df_bw.series_id.values, return_index=True)[1]\n",
    "\n",
    "bingeworthy_series = {translation_series_id_index_urm[series]: bw for series, bw in zip([df_bw.series_id.values[index] for index in sorted(series_indices)],\n",
    "                                              np.array(\n",
    "                                                  df_bw.groupby(\"series_id\").sum().n_bingewatching_sessions_3_to_7.values,\n",
    "                                                  dtype=int))\n",
    "                    if bw != 0}\n",
    "\n",
    "URM_bingeworthy_row_array = np.zeros((1, URM_train.shape[1]), dtype=int)\n",
    "\n",
    "for k, i in bingeworthy_series.items():\n",
    "    URM_bingeworthy_row_array[k] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.interactions\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.metadata)\n",
    "# dataset.metadata[\"num_items\"] = dataset.interactions.item_id.nunique()\n",
    "# dataset.metadata[\"num_recommendations\"] = dataset.interactions.recommendation_id.nunique()\n",
    "# dataset.metadata[\"num_series\"] = dataset.interactions.user_id.nunique()\n",
    "# dataset.metadata[\"num_users\"] = dataset.interactions.series_id.nunique()\n",
    "# print(dataset.metadata)\n",
    "# dataset.save_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.interactions = clean_dataset_CW_class(dataset.interactions)\n",
    "dataset.interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.interactions\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[(d[\"interaction_type\"] == 0) & (d[\"vision_factor\"] >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_after_filtering(d, d[(d[\"interaction_type\"] == 0) & (d[\"vision_factor\"] >= 0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[(d[\"interaction_type\"] == 0) & (d[\"vision_factor\"] >= 0.9)]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = user_temporal_split(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_statistics(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_statistics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_statistics(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_dataset_statistics(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(set(test.user_id) - set(train.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[(test[\"user_id\"].isin(train.user_id)) & (test[\"series_id\"].isin(train.series_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation[(validation[\"user_id\"].isin(train.user_id) & (validation[\"series_id\"].isin(train.series_id)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[test[\"user_id\"].isin(train.user_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.user_id.nunique(), d.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.user_id.nunique(), train.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.user_id.nunique(), validation.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.user_id.nunique(), test.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user, num_items = train.user_id.nunique(), train.series_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URM_train = np.zeros(shape=(num_user, num_items))\n",
    "URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_chunks = separate_dataset_into_chunks(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_chunks[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(train.user_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(train.user_id.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resort table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ids, s_ids = np.unique(train.user_id.values), np.unique(train.series_id.values)\n",
    "URM_index_user_id_correspondence_dict = {u_ids[i]: i for i in range(len(u_ids))}\n",
    "URM_index_series_id_correspondence_dict = {s_ids[i]: i for i in range(len(s_ids))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in tqdm(train_chunks):\n",
    "    URM_train[URM_index_user_id_correspondence_dict[chunk.user_id.values[0]], URM_index_series_id_correspondence_dict[chunk.series_id.values[0]]] = len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in URM_index_series_id_correspondence_dict.items():\n",
    "    if v == 18089:\n",
    "        s = k\n",
    "print(s)\n",
    "for k, v in URM_index_user_id_correspondence_dict.items():\n",
    "    if v == 38874:\n",
    "        u = k\n",
    "train[(train[\"user_id\"] == u) & (train[\"series_id\"] == s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_train[38874, 18089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(URM_train > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from SerialContentAnalysisFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/ContentWiseImpressions/CW10M-CSV/interactions.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataset_CW_class(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_50_4h = get_timestamp_differential_dataframe(df=df, percentage=50, session_threshold_hours=2, train=True, store=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_50_2h = get_timestamp_differential_dataframe(df=df, percentage=50, session_threshold_hours=4, train=True, store=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add to the URM train of SLIM ElasticNet one row vector and one column vector:\n",
    "- row vector contains the bingeworthiness of series j\n",
    "- column vector contains if the user i is a bingewatcher or not\n",
    ":param dataset: data\n",
    ":param URM_train:\n",
    ":param percentage_watched:\n",
    ":param hour_threshold:\n",
    ":return:\n",
    "\"\"\"\n",
    "# Retrieve corresponding df bw\n",
    "# if dataset is not None:\n",
    "# df_bw = get_timestamp_differential_dataframe(df=dataset, percentage=percentage_watched, session_threshold_hours=hour_threshold, train=True)\n",
    "df_bw = df_50_2h\n",
    "# else:\n",
    "#     df_bw = get_timestamp_differential_dataframe(percentage=percentage_watched, session_threshold_hours=hour_threshold, use_items=use_items)\n",
    "print(\"Df_bw loaded\")\n",
    "# Generate bingewatchers column to be addedat the right of the URM\n",
    "user_indices = np.unique(df_bw.user_id.values, return_index=True)[1]\n",
    "\n",
    "bingewatchers = {user: bw for user, bw in zip([df_bw.user_id.values[index] for index in sorted(user_indices)],\n",
    "                                              np.array((df_bw.groupby(\"user_id\").sum().n_bingewatching_sessions_3_to_7 /\n",
    "                                                        df_bw.groupby(\"user_id\").sum().n_sessions).values ,dtype=np.float16))\n",
    "                 if bw != 0}\n",
    "\n",
    "URM_bingewatchers_column_array = np.zeros((URM_train.shape[0]+1, 1), dtype=int)\n",
    "\n",
    "for k, i in bingewatchers.items():\n",
    "    URM_bingewatchers_column_array[k] = i\n",
    "\n",
    "print(URM_bingewatchers_column_array)\n",
    "# Generate bingeworthy row to be added at the bottom of the URM\n",
    "series_indices = np.unique(df_bw.series_id.values, return_index=True)[1]\n",
    "\n",
    "bingeworthy_series = {series: bw for series, bw in zip([df_bw.series_id.values[index] for index in sorted(series_indices)],\n",
    "                                              np.array(\n",
    "                                                  (df_bw.groupby(\"series_id\").sum().n_bingewatching_sessions_3_to_7 /\n",
    "                                                   df_bw.groupby(\"series_id\").sum().n_sessions).values,\n",
    "                                                  dtype=np.float16))\n",
    "                        if bw != 0}\n",
    "\n",
    "URM_bingeworthy_row_array = np.zeros((1, URM_train.shape[1]), dtype=int)\n",
    "\n",
    "for k, i in bingeworthy_series.items():\n",
    "    URM_bingeworthy_row_array[k] = i\n",
    "print(URM_bingeworthy_row_array)\n",
    "\n",
    "# URM_train = URM_train.todense()\n",
    "# URM_train = np.concatenate((URM_train, URM_bingeworthy_row_array), axis=0)\n",
    "# URM_train = np.concatenate((URM_train, URM_bingewatchers_column_array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_50_1h = get_timestamp_differential_dataframe(df=df, percentage=50, session_threshold_hours=1, train=True, store=True)\n",
    "df_50_3h = get_timestamp_differential_dataframe(df=df, percentage=50, session_threshold_hours=3, train=True, store=True)\n",
    "df_50_6h = get_timestamp_differential_dataframe(df=df, percentage=50, session_threshold_hours=6, train=True, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.sum(dataset.URM[\"train\"].todense())) == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.interactions[:int(len(dataset.interactions)*0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a, b, c = np.split(dataset.interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_stackexchange\n",
    "\n",
    "data = fetch_stackexchange('crossvalidated',\n",
    "                           test_set_fraction=0.1,\n",
    "                           indicator_features=False,\n",
    "                           tag_features=True)\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = data['item_features']\n",
    "tag_labels = data['item_feature_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(list(np.sum(item_features.todense(), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((1, 28881))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0: 1, 10230: 1}\n",
    "a[0][[k for k in d.keys()]] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
